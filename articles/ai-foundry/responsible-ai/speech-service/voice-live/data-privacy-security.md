---
title: Data, privacy, and security for Voice live
titleSuffix: Foundry Tools
description: This document details issues for data, privacy, and security for Voice live.
author: PatrickFarley
ms.author: pafarley
manager: nitinme
ms.service: azure-ai-speech
ms.topic: article
ms.date: 09/29/2025
---

# Data, privacy, and security for Azure AI Voice Live API

[!INCLUDE [non-english-translation](../../includes/non-english-translation.md)]

> [!NOTE]
> This article is provided for informational purposes only and not for the purpose of providing legal advice. We strongly recommend seeking specialist legal advice when implementing Speech Services.

This article provides details regarding how data provided by you to the Azure AI Voice Live API ("Voice Live API") is processed, used, and stored.  

Voice Live API is a fully managed Azure service that enables developers to build, deploy, and scale speech-to-speech experiences for voice agents. The service supports multiple natively available language models, such as GPT‑Realtime, GPT‑4.1, GPT‑4o, and GPT‑4o‑mini. You can also connect an agent built with the Foundry Agent Service to add speech input and output, or use a customer‑deployed model hosted in Microsoft Foundry.  
<!-- Edited to remove marketing adjectives and rewrite as factual capability statements -->

Voice Live API stores and processes data to provide the service and to monitor for violations of the applicable [Product Terms](https://www.microsoft.com/licensing/terms/). See also [the Microsoft Products and Services Data Protection Addendum](https://aka.ms/DPA), which governs data processing by the Foundry Tools, including Voice Live API. Voice Live API is an Azure service;[ learn more about applicable Azure compliance offerings](/compliance/regulatory/offering-home). 

> [!IMPORTANT]
> Your prompts (inputs), completions (outputs), and your training data: 
>
> - are NOT available to other customers. 
> - are NOT available to OpenAI or other model providers. 
> - are NOT used to improve OpenAI models or other model providers’ models. 
> - are NOT used to train, retrain, or improve Azure OpenAI Service or Azure Speech in Foundry Tools foundation models. 
> - are NOT used to improve any Microsoft or third-party products or services without your permission or instruction. 
>
> With Voice Live API, your fine-tuned speech models are available exclusively for your use.

The language models provided with Voice Live API are operated by Microsoft as an Azure service. If you choose to bring your own agent created with [Agent Service](/azure/ai-foundry/agents/overview) or bring your deployed model in [Foundry Models](/azure/ai-foundry/concepts/foundry-models-overview) to Voice Live API, additional information on data, privacy, and security is available at [Data, privacy, and security for Agent Service](/azure/ai-foundry/responsible-ai/agents/data-privacy-security) and [Data, privacy, and security for use of models through the model catalog in Foundry](/azure/ai-foundry/how-to/concept-data-privacy).

## What data does Azure AI Voice live API process?

Voice Live API processes the following types of data: 

- **Prompts and output**. Prompts are submitted by the user, and content is generated by the GenAI model selected and converted to audio with or without avatar by Voice Live API. 
- **Uploaded data**. You can provide your own data for use with Voice Live API using your own Azure Storage account or a configured data store, for example, your custom lexicon file to improve the pronunciation of the text to speech output, or your text and speech data to fine-tune the speech to text, text to speech and avatar model.  
- **External data**. When you use the tools that support function calling, the service processes the outputs of those tools. 

> [!IMPORTANT]
> Custom neural voice ("custom voice") and custom avatar are available with [limited access](/azure/ai-foundry/responsible-ai/speech-service/text-to-speech/limited-access?tabs=cnv). Learn more about data processing, storage and retention for [custom text to speech (custom voice)](/azure/ai-foundry/responsible-ai/speech-service/text-to-speech/data-privacy-security?tabs=custom-neural-voice#recorded-acknowledgement-statement-verification) and [custom avatar](/azure/ai-foundry/responsible-ai/speech-service/text-to-speech/data-privacy-security?tabs=custom-avatar#video-acknowledgement-statement-verification).  

## How does Azure AI Voice live API process data?

The diagram below shows the data processing workflow for Voice Live API. It depicts how the API handles prompts (user audio input) through inferencing to produce content (agent audio output or video output with avatar), as well as how data from external tools is ingested into the service.

:::image type="content" source="media/voice-live-diagram.png" alt-text="Diagram of the Voice live scenario.":::

When these features are enabled by the user, Voice Live API processes audio input for noise suppression, echo cancellation, voice activity detection, and end of utterance detection, prior to sending the audio for speech recognition and language generation. For speech-to-speech models, audio output is generated directly from the language model. If a text-based language model is specified, Voice Live API converts the text response into audio. When an avatar is selected, the service streams the avatar and returns both the audio response and the avatar together.   
<!-- Minor wording tightened to improve clarity and remove unnecessary phrasing -->

When you bring your own model deployed in Foundry or an agent built with Agent Service to Voice Live API, the service interacts with the specified model endpoints to process your input prompts transcribed from audio and generate text output responses, which may then be used by Voice Live API for audio and avatar video generation. Data is processed for model inferencing in accordance with the terms that apply to the relevant model. Learn more at [Data, privacy, and security for Azure OpenAI Service](/azure/ai-foundry/responsible-ai/openai/data-privacy) and [Data, privacy, and security for use of models through the model catalog in Foundry portal](/azure/ai-studio/how-to/concept-data-privacy).

To reduce the risk of harmful use of Voice Live API, the service includes [content filtering](/azure/ai-foundry/openai/concepts/content-filter) support. The outputs processed by the service are filtered according to the content filtering configuration applied to the natively supported models or to the model deployment used by your Foundry Agent.  
<!-- Edited to remove promotional tone and state behavior factually -->

## Data storage and retention  

While Voice Live API itself does not store or retain customer data, the features (for example, custom voice, custom avatar, Foundry Agent) it interacts with may store customer data as required by those features. Check data storage for [custom voice](/azure/ai-foundry/responsible-ai/speech-service/text-to-speech/data-privacy-security?tabs=custom-neural-voice#data-storage-and-retention), [custom avatar](/azure/ai-foundry/responsible-ai/speech-service/text-to-speech/data-privacy-security?tabs=custom-avatar#data-storage-and-retention), [Foundry Agents](/azure/ai-foundry/responsible-ai/agents/data-privacy-security#data-storage-for-azure-ai-agent-service-features), and [Azure OpenAI](/azure/ai-foundry/responsible-ai/openai/data-privacy?tabs=azure-portal#data-storage-for-azure-openai-service-features) if you are using these components. Learn more about [locations of processing for ‘global’ and ‘data zone’ deployments](/azure/ai-foundry/responsible-ai/openai/data-privacy?tabs=azure-portal#understanding-location-of-processing-for-global-and-data-zone-deployment-types).  
<!-- Sentence adjusted to remove promotional phrasing and clarify scope -->

Users can opt into a logging feature for debugging assistance from Microsoft engineers when a [support ticket](/azure/ai-services/cognitive-services-support-options?context=%2Fazure%2Fai-services%2Fspeech-service%2Fcontext%2Fcontext#create-an-azure-support-request) is filed. With this logging feature, users’ speech data is secured and stored in Azure storage managed by Microsoft within the same resource region. Microsoft debugging engineers are authorized Microsoft employees who access the data through point‑in‑time queries using request IDs, Secure Access Workstations (SAWs), and Just‑In‑Time (JIT) approval granted by team managers. These logs are automatically removed 30 days after they are generated.  
<!-- Rewritten to be more concise and factual -->

To learn more about Microsoft's privacy and security commitments, visit the [Microsoft Trust Center](https://www.microsoft.com/TrustCenter/CloudServices/Azure/default.aspx).