---
title: Include file
description: Include file
ms.author: mopeakande
author: msakande
ms.service: azure-ai-foundry
ms.topic: include
ms.date: 06/13/2025
ms.custom: include
---

> [!NOTE]
> We recommend that you deploy Azure AI Foundry Models to **Azure AI Foundry resources** so that you can consume your deployments in the resource via a single endpoint with the same authentication and schema to generate inference. The endpoint follows the [Azure AI Model Inference API](/rest/api/aifoundry/modelinference/) which all the Foundry Models support. To learn how to deploy a Foundry Model to the Azure AI Foundry resources, see [Add and configure models to Azure AI Foundry Models](../model-inference/how-to/create-model-deployments.md).