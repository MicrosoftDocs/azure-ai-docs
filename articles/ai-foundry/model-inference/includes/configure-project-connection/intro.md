---
manager: nitinme
author: santiagxf
ms.author: fasantia 
ms.service: azure-ai-model-inference
ms.date: 1/21/2025
ms.topic: include
---

[!INCLUDE [Feature preview](../../../includes/feature-preview.md)]

You can use Azure AI model inference in your projects in Azure AI Foundry to create reach applications and interact/manage the models available. To use the Azure AI model inference service in your project, you need to create a connection to the Azure AI Services resource.

The following article explains how to create a connection to the Azure AI Services resource to use the inference endpoint.

## Prerequisites

To complete this article, you need:

* An Azure subscription. If you're using [GitHub Models](https://docs.github.com/en/github-models/), you can upgrade your experience and create an Azure subscription in the process. Read [Upgrade from GitHub Models to Azure AI model inference](../../how-to/quickstart-github-models.md) if that's your case.

* An Azure AI services resource. See [Create an Azure AI Services resource](../../../../ai-services/multi-service-resource.md??context=/azure/ai-services/model-inference/context/context) for more details.