---
title: "Tutorial: Run TensorFlow model in Python - Custom Vision Service"
titleSuffix: Azure AI services
description: Run a TensorFlow model in Python. This article only applies to models exported from image classification projects in the Custom Vision service.
author: PatrickFarley
manager: nitinme
#customer intent: As a developer, I want to run a TensorFlow model in Python so that I can classify images locally.

ms.service: azure-ai-custom-vision
ms.topic: how-to
ms.date: 01/29/2025
ms.author: pafarley
ms.devlang: python
ms.custom: devx-track-python
---

# Run a TensorFlow model in Python

This guide shows you how to use an [exported TensorFlow model](./export-your-model.md) locally to classify images.

> [!NOTE]
> This guide only applies to models exported from "General (compact)" image classification projects. If you exported other models, please visit our [sample code repository](https://github.com/Azure-Samples/customvision-export-samples).

## Prerequisites

- Install either Python 2.7+ or Python 3.6+.
- Install pip.
- Then install the following packages:
    ```bash
    pip install tensorflow
    pip install pillow
    pip install numpy
    pip install opencv-python
    ```

## Load your model and tags

The downloaded _.zip_ file from the export step contains a _model.pb_ and a _labels.txt_ file. These files represent the trained model and the classification labels. The first step is to load the model into your project. Add the following code to a new Python script.

```Python
import tensorflow as tf
import os

graph_def = tf.compat.v1.GraphDef()
labels = []

# These are set to the default names from exported models, update as needed.
filename = "model.pb"
labels_filename = "labels.txt"

# Import the TF graph
with tf.io.gfile.GFile(filename, 'rb') as f:
    graph_def.ParseFromString(f.read())
    tf.import_graph_def(graph_def, name='')

# Create a list of labels.
with open(labels_filename, 'rt') as lf:
    for l in lf:
        labels.append(l.strip())
```

## Prepare an image for prediction

There are a few steps you need to take to prepare an image for prediction. These steps mimic the image manipulation performed during training.

1. Open the file and create an image in the BGR color space

    ```Python
    from PIL import Image
    import numpy as np
    import cv2

    # Load from a file
    imageFile = "<path to your image file>"
    image = Image.open(imageFile)

    # Update orientation based on EXIF tags, if the file has orientation info.
    image = update_orientation(image)

    # Convert to OpenCV format
    image = convert_to_opencv(image)
    ```

1. If the image has a dimension greater than 1600 pixels, call this method (defined later on).

    ```Python
    image = resize_down_to_1600_max_dim(image)
    ```

1. Crop the largest center square

    ```Python
    h, w = image.shape[:2]
    min_dim = min(w,h)
    max_square_image = crop_center(image, min_dim, min_dim)
    ```

1. Resize that square down to 256x256

    ```Python
    augmented_image = resize_to_256_square(max_square_image)
    ```

1. Crop the center for the specific input size for the model

    ```Python
    # Get the input size of the model
    with tf.compat.v1.Session() as sess:
        input_tensor_shape = sess.graph.get_tensor_by_name('Placeholder:0').shape.as_list()
    network_input_size = input_tensor_shape[1]

    # Crop the center for the specified network_input_Size
    augmented_image = crop_center(augmented_image, network_input_size, network_input_size)

    ```

1. Define helper functions. The steps above use the following helper functions:

    ```Python
    def convert_to_opencv(image):
        # RGB -> BGR conversion is performed as well.
        image = image.convert('RGB')
        r,g,b = np.array(image).T
        opencv_image = np.array([b,g,r]).transpose()
        return opencv_image

    def crop_center(img,cropx,cropy):
        h, w = img.shape[:2]
        startx = w//2-(cropx//2)
        starty = h//2-(cropy//2)
        return img[starty:starty+cropy, startx:startx+cropx]

    def resize_down_to_1600_max_dim(image):
        h, w = image.shape[:2]
        if (h < 1600 and w < 1600):
            return image

        new_size = (1600 * w // h, 1600) if (h > w) else (1600, 1600 * h // w)
        return cv2.resize(image, new_size, interpolation = cv2.INTER_LINEAR)

    def resize_to_256_square(image):
        h, w = image.shape[:2]
        return cv2.resize(image, (256, 256), interpolation = cv2.INTER_LINEAR)

    def update_orientation(image):
        exif_orientation_tag = 0x0112
        if hasattr(image, '_getexif'):
            exif = image._getexif()
            if (exif != None and exif_orientation_tag in exif):
                orientation = exif.get(exif_orientation_tag, 1)
                # orientation is 1 based, shift to zero based and flip/transpose based on 0-based values
                orientation -= 1
                if orientation >= 4:
                    image = image.transpose(Image.TRANSPOSE)
                if orientation == 2 or orientation == 3 or orientation == 6 or orientation == 7:
                    image = image.transpose(Image.FLIP_TOP_BOTTOM)
                if orientation == 1 or orientation == 2 or orientation == 5 or orientation == 6:
                    image = image.transpose(Image.FLIP_LEFT_RIGHT)
        return image
    ```

## Classify an image

Once the image is prepared as a tensor, we can send it through the model for a prediction.

```Python
# These names are part of the model and cannot be changed.
output_layer = 'loss:0'
input_node = 'Placeholder:0'

with tf.compat.v1.Session() as sess:
    try:
        prob_tensor = sess.graph.get_tensor_by_name(output_layer)
        predictions = sess.run(prob_tensor, {input_node: [augmented_image] })
    except KeyError:
        print ("Couldn't find classification output layer: " + output_layer + ".")
        print ("Verify this a model exported from an Object Detection project.")
        exit(-1)
```

## Display the results

The results of running the image tensor through the model will then need to be mapped back to the labels.

```Python
    # Print the highest probability label
    highest_probability_index = np.argmax(predictions)
    print('Classified as: ' + labels[highest_probability_index])
    print()

    # Or you can print out all of the results mapping labels to probabilities.
    label_index = 0
    for p in predictions:
        truncated_probablity = np.float64(np.round(p,8))
        print (labels[label_index], truncated_probablity)
        label_index += 1
```

## Related content

Next, learn how to wrap your model into a mobile application:
* [Use your exported TensorFlow model in an Android application](https://github.com/Azure-Samples/cognitive-services-android-customvision-sample)
* [Use your exported CoreML model in a Swift iOS application](https://go.microsoft.com/fwlink/?linkid=857726)
